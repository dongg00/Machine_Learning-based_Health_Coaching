{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd713f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.impute import KNNImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec58027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic' # 예시: 맑은 고딕으로 설정 (Windows 환경 시)\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8156392",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"건강데이터_2022_2023_합본.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90b9ef39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LS_VEG1\n",
       "2.0     5685\n",
       "1.0     5482\n",
       "3.0     1234\n",
       "5.0      121\n",
       "4.0       80\n",
       "6.0       13\n",
       "7.0        4\n",
       "9.0        4\n",
       "99.0       4\n",
       "8.0        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['LS_VEG1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1128f230",
   "metadata": {},
   "source": [
    "전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0180f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BE5_1'] = data['BE5_1'].astype(str).str.strip().replace({ #1주일간 근력운동 일수\n",
    "'1.0' : 0,\n",
    "'2.0' : 1,\n",
    "'3.0' : 2,\n",
    "'4.0' : 3,\n",
    "'5.0' : 4,\n",
    "'6.0' : 5,\n",
    "'8.0' : 0,\n",
    "'9.0' : np.nan,\n",
    "'nan' : np.nan\n",
    " })\n",
    "data['BE5_1'] = pd.to_numeric(data['BE5_1'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46d8d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LS_VEG1'] = data['LS_VEG1'].astype(str).str.strip().replace({  #최근 1년 동안 평균 채소류(김치 및 장아찌 제외), 버섯류, 해조류 섭취 빈도\n",
    "'1.0' : 1095,\n",
    "'2.0' : 730,\n",
    "'3.0' : 365,\n",
    "'4.0' : 286,\n",
    "'5.0' : 156,\n",
    "'6.0' : 52,\n",
    "'7.0' : 30,\n",
    "'8.0' : 12,\n",
    "'9.0' : 6,\n",
    "'99.0': np.nan,\n",
    "'nan' : np.nan\n",
    "})\n",
    "data['LS_VEG1'] = pd.to_numeric(data['LS_VEG1'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b540e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반 담배 하루 평균 흡연량 처리\n",
    "data['BS3_2'] = data['BS3_2'].replace(888, 0)\n",
    "\n",
    "# 전자 담배 하루 평균 흡연량 처리\n",
    "data['BS12_47_1'] = data['BS12_47_1'].replace({888: 0, 999: np.nan}) \n",
    "\n",
    "# 합치기 전 숫자형으로 변환\n",
    "data['BS3_2'] = pd.to_numeric(data['BS3_2'], errors='coerce')\n",
    "data['BS12_47_1'] = pd.to_numeric(data['BS12_47_1'], errors='coerce')\n",
    "\n",
    "# 두 변수 합산 (NaN은 무시하고 합함)\n",
    "data['tobacco'] = data[['BS3_2', 'BS12_47_1']].sum(axis=1, skipna=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a163f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BD1_11'] = data['BD1_11'].astype(str).str.strip().replace({ #1년간 음주빈도\n",
    "'1.0' : 0,\n",
    "'2.0' : 6,\n",
    "'3.0' : 12,\n",
    "'4.0' : 42,\n",
    "'5.0' : 130,\n",
    "'6.0' : 286,\n",
    "'8.0' : 0,\n",
    "'9.0' : np.nan,\n",
    "'nan' : np.nan\n",
    "})\n",
    "data['BD1_11'] = pd.to_numeric(df['BD1_11'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 결측치 비율 25% 이상인 컬럼 제거\n",
    "missing_ratio = data.isnull().mean()\n",
    "columns_to_drop = [col for col in ['HE_Ualb', 'HE_HTG'] if missing_ratio[col] > 0.25]\n",
    "data = data.drop(columns=columns_to_drop, errors='ignore')\n",
    "print(f\"Removed columns: {columns_to_drop}\")\n",
    "\n",
    "\n",
    "# HE_DM_HbA1c\n",
    "if 'HE_DM_HbA1c' in data.columns:\n",
    "    data['HE_DM_HbA1c'] = data['HE_DM_HbA1c'].replace([9, 99, 999, 888, 9.0, 99.0, 999.0, 888.0], np.nan)\n",
    "    if 'DE1_dg' in data.columns:\n",
    "        print(f\"DE1_dg missing ratio: {data['DE1_dg'].isnull().mean()}\")\n",
    "        data['HE_DM_HbA1c'] = data['HE_DM_HbA1c'].fillna(data['DE1_dg'].map({0: 1, 1: 3}))\n",
    "    # 남은 결측치는 클래스 비율 기반 랜덤 샘플링\n",
    "    if data['HE_DM_HbA1c'].isnull().any():\n",
    "        class_probs = data['HE_DM_HbA1c'].value_counts(normalize=True)\n",
    "        data['HE_DM_HbA1c'] = data['HE_DM_HbA1c'].apply(\n",
    "            lambda x: np.random.choice(class_probs.index, p=class_probs.values) if pd.isna(x) else x\n",
    "        )\n",
    "    print(f\"HE_DM_HbA1c NaN count after: {data['HE_DM_HbA1c'].isnull().sum()}\")\n",
    "\n",
    "# HE_obe\n",
    "if 'HE_obe' in data.columns:\n",
    "    data['HE_obe'] = data['HE_obe'].replace([9, 99, 999, 888, 9.0, 99.0, 999.0, 888.0], np.nan)\n",
    "    if 'HE_BMI' in data.columns:\n",
    "        # BMI가 KNN 대체된 경우 표시\n",
    "        data['HE_BMI_imputed'] = data['HE_BMI'].isnull().astype(int)\n",
    "        data['HE_obe'] = data.apply(\n",
    "            lambda row: row['HE_obe'] if pd.notna(row['HE_obe']) else (\n",
    "                1 if row['HE_BMI'] < 18.5 else\n",
    "                2 if row['HE_BMI'] < 25 else\n",
    "                3 if row['HE_BMI'] < 30 else\n",
    "                4 if row['HE_BMI'] < 35 else\n",
    "                5 if row['HE_BMI'] < 40 else\n",
    "                6\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "    # 남은 결측치는 클래스 비율 기반 랜덤 샘플링\n",
    "    if data['HE_obe'].isnull().any():\n",
    "        class_probs = data['HE_obe'].value_counts(normalize=True)\n",
    "        data['HE_obe'] = data['HE_obe'].apply(\n",
    "            lambda x: np.random.choice(class_probs.index, p=class_probs.values) if pd.isna(x) else x\n",
    "        )\n",
    "    print(f\"HE_obe NaN count after: {data['HE_obe'].isnull().sum()}\")\n",
    "\n",
    "# HE_HP\n",
    "if 'HE_HP' in data.columns:\n",
    "    data['HE_HP'] = data['HE_HP'].replace([9, 99, 999, 888, 9.0, 99.0, 999.0, 888.0], np.nan)\n",
    "    if 'DI1_dg' in data.columns:\n",
    "        print(f\"DI1_dg missing ratio: {data['DI1_dg'].isnull().mean()}\")\n",
    "        data['HE_HP'] = data['HE_HP'].fillna(data['DI1_dg'].map({0: 1, 1: 4}))\n",
    "    # 남은 결측치는 클래스 비율 기반 랜덤 샘플링\n",
    "    if data['HE_HP'].isnull().any():\n",
    "        class_probs = data['HE_HP'].value_counts(normalize=True)\n",
    "        data['HE_HP'] = data['HE_HP'].apply(\n",
    "            lambda x: np.random.choice(class_probs.index, p=class_probs.values) if pd.isna(x) else x\n",
    "        )\n",
    "    print(f\"HE_HP NaN count after: {data['HE_HP'].isnull().sum()}\")\n",
    "\n",
    "#결측치 비율 낮은 변수 처리\n",
    "    low_missing_columns = [\n",
    "    'incm', 'ho_incm', 'edu', 'occp', 'HE_fh', 'D_1_1', 'DI1_dg', 'DI1_ag', 'DI1_pr', 'DI1_pt', 'DI1_2',\n",
    "    'DI2_dg', 'DI2_ag', 'DI2_pr', 'DI2_pt', 'DI2_2', 'DE1_dg', 'DE1_ag', 'DE1_pr', 'DE1_pt', 'DE1_3',\n",
    "    'DE1_31', 'DE1_32', 'DE1_33', 'DE1_34', 'DE1_4', 'DN1_dg', 'DN1_ag', 'BH1', 'BO1', 'BO1_1', 'BO2_1',\n",
    "    'BD1', 'BD1_11', 'BD2_1', 'BP16_1', 'BP16_2', 'BP1', 'BP5', 'BS1_1', 'BS3_1', 'BS3_2', 'BS12_37',\n",
    "    'BS12_47', 'BS12_47_1', 'BS12_1', 'BS12_2', 'BE3_31', 'BE3_32', 'BE3_33', 'BE5_1', 'BE9', 'L_BR_FQ',\n",
    "    'L_LN_FQ', 'L_DN_FQ', 'L_OUT_FQ', 'LS_VEG1', 'LS_FRUIT'\n",
    "]\n",
    "continuous_columns = ['HE_wt', 'HE_ht', 'HE_BMI']  # 연속형 변수\n",
    "\n",
    "for col in low_missing_columns + continuous_columns:\n",
    "    if col in data.columns:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "        data[col] = data[col].replace([9, 99, 999, 88, 888, 9.0, 99.0, 999.0, 88.0, 888.0], np.nan)\n",
    "        if not data[col].isnull().all():\n",
    "            if col in continuous_columns:\n",
    "                median_value = data[col].median()\n",
    "                data[col] = data[col].fillna(median_value)\n",
    "                print(f\"Median for {col}: {median_value}\")\n",
    "            else:\n",
    "                mode_series = data[col].mode(dropna=True)\n",
    "                if not mode_series.empty:\n",
    "                    mode_value = mode_series[0]\n",
    "                    data[col] = data[col].fillna(mode_value)\n",
    "                    print(f\"Mode for {col}: {mode_value}\")\n",
    "                else:\n",
    "                    print(f\"No valid mode for {col}, leaving as is.\")\n",
    "        else:\n",
    "            print(f\"Column {col} is all NaN, skipping.\")\n",
    "\n",
    "#생체 지표 결측치 처리\n",
    "knn_columns = [\n",
    "    'HE_sbp1', 'HE_dbp1', 'HE_sbp2', 'HE_dbp2', 'HE_wc', 'HE_glu', 'HE_HbA1c', 'HE_chol',\n",
    "    'HE_HDL_st2', 'HE_TG', 'HE_LDL_drct', 'HE_HCHOL', 'HE_BUN', 'HE_crea', 'HE_Upro', 'HE_Ucrea',\n",
    "    'HE_ast', 'HE_alt', 'HE_wt', 'HE_ht', 'HE_BMI'\n",
    "]\n",
    "knn_data = data[knn_columns].copy()\n",
    "knn_data = knn_data.replace([888, 999, 888.0, 999.0], np.nan)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "knn_data_scaled = scaler.fit_transform(knn_data)\n",
    "knn_data_scaled = pd.DataFrame(knn_data_scaled, columns=knn_columns, index=knn_data.index)\n",
    "\n",
    "# KNN Imputation\n",
    "imputer_knn = KNNImputer(n_neighbors=5, weights=\"distance\")\n",
    "knn_imputed = imputer_knn.fit_transform(knn_data_scaled)\n",
    "\n",
    "# 역스케일링\n",
    "knn_imputed = scaler.inverse_transform(knn_imputed)\n",
    "knn_imputed_data = pd.DataFrame(knn_imputed, columns=knn_columns, index=knn_data.index)\n",
    "data[knn_columns] = knn_imputed_data\n",
    "\n",
    "# knn_scaler_filename = 'HE_DM_HbA1c_knn_scaler.pkl'\n",
    "# knn_imputer_filename = 'HE_DM_HbA1c_knn_imputer.pkl'\n",
    "# joblib.dump(knn_data_scaled, knn_scaler_filename)\n",
    "# joblib.dump(imputer_knn, knn_imputer_filename)\n",
    "# knn_scaler_filename = 'HE_obe_knn_scaler.pkl'\n",
    "# knn_imputer_filename = 'HE_obe_knn_imputer.pkl'\n",
    "# joblib.dump(knn_data_scaled, knn_scaler_filename)\n",
    "# joblib.dump(imputer_knn, knn_imputer_filename)\n",
    "# knn_scaler_filename = 'HE_HP_knn_scaler.pkl'\n",
    "# knn_imputer_filename = 'HE_HP_knn_imputer.pkl'\n",
    "# joblib.dump(knn_data_scaled, knn_scaler_filename)\n",
    "# joblib.dump(imputer_knn, knn_imputer_filename)\n",
    "\n",
    "print(\"결측치 처리 후 데이터 상태:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"\\n타겟 변수 클래스 비율:\")\n",
    "for target in ['HE_DM_HbA1c', 'HE_obe', 'HE_HP']:\n",
    "    if target in data.columns:\n",
    "        print(f\"\\n{target}:\\n{data[target].value_counts(normalize=True)}\")\n",
    "print(\"\\n기본 통계량:\")\n",
    "print(data.describe())\n",
    "data.to_csv('processed_dataset_real2.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2710405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/건강검진/health_checkup/JDM/Real/df_clustering_filled.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312ff2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
